{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tokenizers\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import transformers\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy (you can see that it is pretty easy to set up).\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set (always set in Kaggle)\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'camembert-base'\n",
    "MAX_LEN = 256\n",
    "ARTIFACTS_PATH = '../artifacts/'\n",
    "\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 6\n",
    "\n",
    "if not os.path.exists(ARTIFACTS_PATH):\n",
    "    os.makedirs(ARTIFACTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roberta_encode(texts, tokenizer):\n",
    "    ct = len(texts)\n",
    "    input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
    "    attention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "    token_type_ids = np.zeros((ct, MAX_LEN), dtype='int32') # Not used in text classification\n",
    "\n",
    "    for k, text in enumerate(texts):\n",
    "        # Tokenize\n",
    "        tok_text = tokenizer.tokenize(text)\n",
    "        \n",
    "        # Truncate and convert tokens to numerical IDs\n",
    "        enc_text = tokenizer.convert_tokens_to_ids(tok_text[:(MAX_LEN-2)])\n",
    "        \n",
    "        input_length = len(enc_text) + 2\n",
    "        input_length = input_length if input_length < MAX_LEN else MAX_LEN\n",
    "        \n",
    "        # Add tokens [CLS] and [SEP] at the beginning and the end\n",
    "        input_ids[k,:input_length] = np.asarray([0] + enc_text + [2], dtype='int32')\n",
    "        \n",
    "        # Set to 1s in the attention input\n",
    "        attention_mask[k,:input_length] = 1\n",
    "\n",
    "    return {\n",
    "        'input_word_ids': input_ids,\n",
    "        'input_mask': attention_mask,\n",
    "        'input_type_ids': token_type_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tokenizer from HuggingFace\n",
    "from transformers import CamembertForMaskedLM\n",
    "from transformers import CamembertTokenizer\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = CamembertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "text = pd.read_csv('./Post_Data/Testing_data.csv')\n",
    "text = text[['text']].to_numpy().reshape(-1)\n",
    "text = roberta_encode(text, tokenizer)\n",
    "\n",
    "model= load_model('./Post_Data/model.h5')\n",
    "y_pred = model.predict(text)\n",
    "y_pred_max = [np.argmax(i) for i in y_pred]\n",
    "\n",
    "y_pred_fin = [category_to_name[i] for i in y_pred_max]\n",
    "\n",
    "df = pd.DataFrame(y_pred_fin)\n",
    "df.to_csv('./Post_Data/Output.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model = tf.keras.models.load_model('./Post_Data/model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = saved_model.load_model('./Post_Data/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Camem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0112a2845a759dc901fe0a21d348bab05a5dd04984f6eacd72c02dbb62a5c612"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
