{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Post_Data/TRAINING2.csv')\n",
    "df.drop(df[(df[\"culture\"] == \"nl-nl\")].index, inplace = True)\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stopwords = nltk.corpus.stopwords.words('french')\n",
    "mots = set(line.strip() for line in open('dictionnaire.txt', encoding=\"utf8\"))\n",
    "lemmatizer = FrenchLefffLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def French_Preprocess_listofSentence(listofSentence):\n",
    " preprocess_list = []\n",
    " for sentence in listofSentence :\n",
    "  sentence_w_punct = \"\".join([i.lower() for i in sentence if i not in string.punctuation])\n",
    "  sentence_w_num = ''.join(i for i in sentence_w_punct if not i.isdigit())\n",
    "  tokenize_sentence = nltk.tokenize.word_tokenize(sentence_w_num)\n",
    "  words_w_stopwords = [i for i in tokenize_sentence if i not in french_stopwords]\n",
    "  words_lemmatize = (lemmatizer.lemmatize(w) for w in words_w_stopwords)\n",
    "  sentence_clean = ' '.join(w for w in words_lemmatize if w.lower() in mots or not w.isalpha())\n",
    "  preprocess_list.append(sentence_clean)\n",
    " return preprocess_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_preprocess_list = French_Preprocess_listofSentence(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv = pd.DataFrame(french_preprocess_list)\n",
    "save_csv = pd.concat([df[\"label\"], save_csv], axis=1)\n",
    "save_csv = save_csv.rename(columns={0: \"text\"})\n",
    "save_csv.to_csv('french_preprocess_list_jorg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NLP-ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12518f93acdd6b7d1943c610b6ce0874ef8a914b22b93bf6bcdfddea2c050673"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
