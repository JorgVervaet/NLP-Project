{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.roberta import CamembertModel\n",
    "camembert = CamembertModel.from_pretrained('./Camembert-base/')\n",
    "camembert.eval()\n",
    "masked_line = 'Le camembert est <mask> :)'\n",
    "camembert.fill_mask(masked_line, topk=3)\n",
    "\n",
    "# The underlying model is available under the *models* attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers.modeling_camembert import CamembertForMaskedLM\n",
    "from transformers.tokenization_camembert import CamembertTokenizer\n",
    "\n",
    "\n",
    "def fill_mask(masked_input, model, tokenizer, topk=5):\n",
    "    # Adapted from https://github.com/pytorch/fairseq/blob/master/fairseq/models/roberta/hub_interface.py\n",
    "    assert masked_input.count(\"<mask>\") == 1\n",
    "    input_ids = torch.tensor(tokenizer.encode(masked_input, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    logits = model(input_ids)[0]  # The last hidden-state is the first element of the output tuple\n",
    "    masked_index = (input_ids.squeeze() == tokenizer.mask_token_id).nonzero().item()\n",
    "    logits = logits[0, masked_index, :]\n",
    "    prob = logits.softmax(dim=0)\n",
    "    values, indices = prob.topk(k=topk, dim=0)\n",
    "    topk_predicted_token_bpe = \" \".join(\n",
    "        [tokenizer.convert_ids_to_tokens(indices[i].item()) for i in range(len(indices))]\n",
    "    )\n",
    "    masked_token = tokenizer.mask_token\n",
    "    topk_filled_outputs = []\n",
    "    for index, predicted_token_bpe in enumerate(topk_predicted_token_bpe.split(\" \")):\n",
    "        predicted_token = predicted_token_bpe.replace(\"\\u2581\", \" \")\n",
    "        if \" {0}\".format(masked_token) in masked_input:\n",
    "            topk_filled_outputs.append(\n",
    "                (\n",
    "                    masked_input.replace(\" {0}\".format(masked_token), predicted_token),\n",
    "                    values[index].item(),\n",
    "                    predicted_token,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            topk_filled_outputs.append(\n",
    "                (masked_input.replace(masked_token, predicted_token), values[index].item(), predicted_token,)\n",
    "            )\n",
    "    return topk_filled_outputs\n",
    "\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "model.eval()\n",
    "\n",
    "masked_input = \"Le camembert est <mask> :)\"\n",
    "print(fill_mask(masked_input, model, tokenizer, topk=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv('./Post_Data/Training_data.csv')\n",
    "\n",
    "# Initializing a RoBERTa configuration\n",
    "configuration = RobertaConfig()\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "model = RobertaModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "print(tokenizer(\"Hello world\")['input_ids'])\n",
    "print(tokenizer(\" Hello world\")['input_ids'])\n",
    "print(csv)\n",
    "\n",
    "for i in csv['text']:\n",
    "    print(tokenizer(i)['input_ids'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForTokenClassification\n",
    "import torch\n",
    "\n",
    "#tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model = CamembertForTokenClassification.from_pretrained('camembert-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "csv = pd.read_csv('./Post_Data/Training_data.csv')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "\n",
    "\n",
    "##### Process text sample (from wikipedia)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "OPTIMIZER =  tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cmarkea/distilcamembert-base-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cmarkea/distilcamembert-base-sentiment\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "nlp(\"Je deteste ce film\")\n",
    "\n",
    "OPTIMIZER =  tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('CamemBERT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "486b0e0edd4f9c3deb84fbdbb1a71a0d22dc9a3de96515e081bea437ec89d2f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
